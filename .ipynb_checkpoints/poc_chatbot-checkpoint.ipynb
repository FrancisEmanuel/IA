{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZtAhAf2f6Mq"
   },
   "source": [
    "## **Poc Chatbot**\n",
    "### Francis Emanuel Oliveira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAHhQkL8hCYE"
   },
   "source": [
    " Carregamos as Bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdXuoNA4DuAL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gmJuBUFNkVQg"
   },
   "source": [
    "O NLTK vem com coleção de textos, gramáticas, modelos treinados, etc. Nessa versão estamos usando os seguinte componentes 'punkt','averaged_perceptron_tagger','wordnet','stopwords', 'floresta'. Nas versões posteriores vamos instalando o que for necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "pvIXaOasJ_2q",
    "outputId": "36b9df43-ef79-4559-abd4-392897e6c216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/floresta.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('floresta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FHESyr3RoMTw"
   },
   "source": [
    "Carrega em df a tabela Book.xlsx <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "05fcxBiBG8t3",
    "outputId": "03fce59d-87b7-48b5-d336-09c3a861036e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pergunta</th>\n",
       "      <th>Resposta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O que é IT Labs?</td>\n",
       "      <td>O IT Labs é a célula de inovação da TI. Para s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qual é a função do IT Labs?</td>\n",
       "      <td>O IT Labs é a célula de inovação da TI. Suas p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Onde fica o IT Labs?</td>\n",
       "      <td>No F-59, em SJK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Em quê unidade fica o IT Labs?</td>\n",
       "      <td>Na unidade de SJK.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Em quê prédio fica o IT Labs?</td>\n",
       "      <td>No F-59, em SJK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Pergunta                                           Resposta\n",
       "0                O que é IT Labs?  O IT Labs é a célula de inovação da TI. Para s...\n",
       "1     Qual é a função do IT Labs?  O IT Labs é a célula de inovação da TI. Suas p...\n",
       "2            Onde fica o IT Labs?                                    No F-59, em SJK\n",
       "3  Em quê unidade fica o IT Labs?                                 Na unidade de SJK.\n",
       "4   Em quê prédio fica o IT Labs?                                    No F-59, em SJK"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Book.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HwzHf6fWq79m"
   },
   "source": [
    "Essa função normaliza o Texto:\n",
    "\n",
    "\n",
    "1.   Minúsculo\n",
    "2.   Remove caracteres especiais\n",
    "3.   Lematização: significa deflexionar uma palavra para determinar o seu lema. Por exemplo, 'ter' é a deflexão de 'tiver', 'tenho', 'tinha' e 'tem'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uuzxOaiQJXv6"
   },
   "outputs": [],
   "source": [
    "def text_normalization(text):\n",
    "    text=str(text).lower() # texto em minusculo\n",
    "    spl_char_text=re.sub(r'[^ a-z]','',text) # remove carecteres especiais usando expressão regular\n",
    "    tokens=nltk.word_tokenize(spl_char_text) # tokeniza as palavras\n",
    "    lema=wordnet.WordNetLemmatizer() # inicializa lemmatization \n",
    "    tags_list=pos_tag(tokens,tagset=None) # partes das palavras\n",
    "    lema_words=[]    \n",
    "    for token,pos_token in tags_list:\n",
    "        if pos_token.startswith('V'):  # Verb\n",
    "            pos_val='v'\n",
    "        elif pos_token.startswith('J'): # Adjective\n",
    "            pos_val='a'\n",
    "        elif pos_token.startswith('R'): # Adverb\n",
    "            pos_val='r'\n",
    "        else:\n",
    "            pos_val='n' \n",
    "        lema_token=lema.lemmatize(token,pos_val) # lemmatization\n",
    "        lema_words.append(lema_token) # Colocando o Token lemetizados em uma lista\n",
    "    \n",
    "    return \" \".join(lema_words) # retorna a frase tratada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VIqYac1_Lf7n",
    "outputId": "42df4cbc-fa3e-41be-839a-a5662b2b22c1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'testando a funo de normalizao'"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_normalization('TEstando, a, função, DE, normalização!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrnKrqp5MvCq"
   },
   "outputs": [],
   "source": [
    "def bagofwords(question):\n",
    "  df['lemmatized_text']=df['input'].apply(text_normalization) # aplica os dados do Book.xlsx a função de normalização\n",
    "  stop = stopwords.words('portuguese')\n",
    "  cv = CountVectorizer() # intializing the count vectorizer\n",
    "  X = cv.fit_transform(df['lemmatized_text']).toarray()\n",
    "  features = cv.get_feature_names()\n",
    "  df_bow = pd.DataFrame(X, columns = features)\n",
    "  Q=[]\n",
    "  a=question.split()\n",
    "  for i in a:\n",
    "      if i in stop:\n",
    "          continue\n",
    "      else:\n",
    "          Q.append(i)\n",
    "      b=\" \".join(Q)\n",
    "\n",
    "  Question_lemma = text_normalization(b)\n",
    "  Question_bow = cv.transform([Question_lemma]).toarray()\n",
    "\n",
    "  cosine_value = 1- pairwise_distances(df_bow, Question_bow, metric = 'cosine' )\n",
    "  \n",
    "  df['similarity_bow']=cosine_value\n",
    "  df_simi = pd.DataFrame(df, columns=['output','similarity_bow']) # considerando o valor de similaridade das respostas para a pergunta que fizemos\n",
    "  df_simi_sort = df_simi.sort_values(by='similarity_bow', ascending=False) # classificando os valores\n",
    "  threshold = 0.2 # considerando que o valor de p = smiliaridade é maior que 0.2\n",
    "  df_threshold = df_simi_sort[df_simi_sort['similarity_bow'] > threshold] \n",
    "  index_value = cosine_value.argmax() # retorna o número do índice de maior valor\n",
    "  return df['output'].loc[index_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b886ITErOID0",
    "outputId": "86d3b1ce-cb3b-4633-cddf-fc4fb00f97b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O IT Labs é a célula de inovação da TI. Para saber mais, visite nossa página.\n"
     ]
    }
   ],
   "source": [
    "pergunta = 'Qual o seu nome?'\n",
    "resposta = bagofwords(pergunta)\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jq0YcFUyj9yj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HfCEYNqNkvHa"
   },
   "outputs": [],
   "source": [
    "#!pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "nltk1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
