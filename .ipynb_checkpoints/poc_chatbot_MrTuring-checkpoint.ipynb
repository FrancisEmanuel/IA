{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZtAhAf2f6Mq"
   },
   "source": [
    "## **Poc Chatbot**\n",
    "### Francis Emanuel Oliveira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAHhQkL8hCYE"
   },
   "source": [
    " Carregamos as Bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdXuoNA4DuAL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gmJuBUFNkVQg"
   },
   "source": [
    "Nesse chatbot estou usando os seguinte componentes do NLTK: 'punkt','averaged_perceptron_tagger','wordnet','stopwords', 'floresta'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "pvIXaOasJ_2q",
    "outputId": "1e2e1037-4c8a-49aa-dfdc-f225eff5f28c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]   Package floresta is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('floresta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FHESyr3RoMTw"
   },
   "source": [
    "Carrega em df a tabela Book.xlsx <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "05fcxBiBG8t3",
    "outputId": "eb9c98c0-8567-43d7-8ce1-f55fe2853cd0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qual o seu nome?</td>\n",
       "      <td>Francis Emanuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qual a sua idade?</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Onde você trabalha?</td>\n",
       "      <td>Na Embraer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Onde você nasceu?</td>\n",
       "      <td>Porteirinha - MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Onde você mora?</td>\n",
       "      <td>Montes Claros - MG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 input              output\n",
       "0     Qual o seu nome?     Francis Emanuel\n",
       "1    Qual a sua idade?                  30\n",
       "2  Onde você trabalha?          Na Embraer\n",
       "3    Onde você nasceu?    Porteirinha - MG\n",
       "4      Onde você mora?  Montes Claros - MG"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Book.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HwzHf6fWq79m"
   },
   "source": [
    "Essa função normaliza o Texto:\n",
    "\n",
    "\n",
    "1.   Minúsculo\n",
    "2.   Remove caracteres especiais\n",
    "3.   Lematização: significa deflexionar uma palavra para determinar o seu lema. Por exemplo, 'ter' é a deflexão de 'tiver', 'tenho', 'tinha' e 'tem'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uuzxOaiQJXv6"
   },
   "outputs": [],
   "source": [
    "def text_normalization(text):\n",
    "    text=str(text).lower() # texto em minusculo\n",
    "    spl_char_text=re.sub(r'[^ a-z]','',text) # remove carecteres especiais usando expressão regular\n",
    "    tokens=nltk.word_tokenize(spl_char_text) # tokeniza as palavras\n",
    "    lema=wordnet.WordNetLemmatizer() # inicializa lemmatization \n",
    "    tags_list=pos_tag(tokens,tagset=None) # partes das palavras\n",
    "    lema_words=[]    \n",
    "    for token,pos_token in tags_list:\n",
    "        if pos_token.startswith('V'):  # Verb\n",
    "            pos_val='v'\n",
    "        elif pos_token.startswith('J'): # Adjective\n",
    "            pos_val='a'\n",
    "        elif pos_token.startswith('R'): # Adverb\n",
    "            pos_val='r'\n",
    "        else:\n",
    "            pos_val='n' \n",
    "        lema_token=lema.lemmatize(token,pos_val) # lemmatization\n",
    "        lema_words.append(lema_token) # Colocando o Token lemetizados em uma lista\n",
    "    \n",
    "    return \" \".join(lema_words) # retorna a frase tratada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VIqYac1_Lf7n",
    "outputId": "6c2634cc-6262-4f04-c60a-f88580b35895"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'testando a funo de normalizao'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_normalization('TEstando, a, função, DE, normalização!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrnKrqp5MvCq"
   },
   "outputs": [],
   "source": [
    "def bagofwords(question):\n",
    "  df['lemmatized_text']=df['input'].apply(text_normalization) # aplica os dados do Book.xlsx a função de normalização\n",
    "  stop = stopwords.words('portuguese')\n",
    "  cv = CountVectorizer() # intializing the count vectorizer\n",
    "  X = cv.fit_transform(df['lemmatized_text']).toarray()\n",
    "  features = cv.get_feature_names()\n",
    "  df_bow = pd.DataFrame(X, columns = features)\n",
    "  Q=[]\n",
    "  a=question.split()\n",
    "  for i in a:\n",
    "      if i in stop:\n",
    "          continue\n",
    "      else:\n",
    "          Q.append(i)\n",
    "      b=\" \".join(Q)\n",
    "\n",
    "  Question_lemma = text_normalization(b)\n",
    "  Question_bow = cv.transform([Question_lemma]).toarray()\n",
    "\n",
    "  cosine_value = 1- pairwise_distances(df_bow, Question_bow, metric = 'cosine' )\n",
    "  \n",
    "  df['similarity_bow']=cosine_value\n",
    "  df_simi = pd.DataFrame(df, columns=['output','similarity_bow']) # considerando o valor de similaridade das respostas para a pergunta que fizemos\n",
    "  df_simi_sort = df_simi.sort_values(by='similarity_bow', ascending=False) # classificando os valores\n",
    "  threshold = 0.2 # considerando que o valor de p = smiliaridade é maior que 0.2\n",
    "  df_threshold = df_simi_sort[df_simi_sort['similarity_bow'] > threshold] \n",
    "  index_value = cosine_value.argmax() # retorna o número do índice de maior valor\n",
    "  return df['output'].loc[index_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b886ITErOID0",
    "outputId": "3083e663-167b-44ed-fcc2-81a4c87968a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Francis Emanuel\n"
     ]
    }
   ],
   "source": [
    "pergunta = 'Qual o seu nome?'\n",
    "resposta = bagofwords(pergunta)\n",
    "print(resposta)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "poc_chatbot.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
